
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publication</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Xiao Wang</div>
<div class="menu-item"><a href=".">Home</a></div>
<div class="menu-item"><a href="biography.html">Biography</a></div>
<div class="menu-item"><a href="publications.html" class="current">Publication</a></div>
<div class="menu-item"><a href="Grants.html">Grants</a></div>  
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publication</h1>
</div>
<h2>Preprints</h2>
<ul>
<li><p> J. Ju, X. Wang and D. Xu.<br />
  Online nonmonotone DR submodular maximization in the bandit setting, 2023.</p>
</li>
<li><p> Y. Lian, D. Du, X. Wang, D. Xu and Y. Zhou.<br />
  Stochastic variance reduction for  DR-submodular maximization, 2023.</p>
</li>
<li><p> X. Wang and X. Chen.<br />
  Complexity of finite-sum optimization with nonsmooth composite fnctions and non-Lipschitiz regularization, 2023.</p>
</li>
<li><p> Q. Shi, X. Wang, H. Wang and Y. Zhu.<br />
  Zeroth-order linearized augmented Lagrangian method with reduced dependence on the problem dimension, 2023.</p>
</li>
<li><p> X. Wang.<br />
  Complexities of inexact cubic-regularized primal-dual algorithms for finding second-order stationary points, 2022.</p>
</li>
<li><p> Q. Shi, X. Wang and H. Wang.<br />
  A momemtum-based linearized augmented Lagrangian method for nonconvex constrained stochastic optimization, 2022.</p>
</li>
<li><p> L.Z. Jin and X. Wang.<br />
  Stochastic nested primal-dual method for nonconvex constrained composition optimization, 2022.</p>
</li>
</ul>
<h2>Published</h2>
<ul>
<li><p> J.N. Wang, X. Wang and L.W. Zhang.<br />
  Stochastic regularized Newton methods for nonlinear equations.<br />
  Journal of Scientific Computing, 94(51), 2023.</p>
</li>
<li><p> W.Y. Cheng, X. Wang and X. Chen.<br />
  An interior stochastic gradient method for a class of non-Lipschitz optimization problems.<br />
  Journal of Scientific Computing, 92(42), 2022.</p>
</li>
<li><p> L. Jin and X. Wang.<br />
  A stochastic primal-dual method for a class of nonconvex constrained optimization.<br />
  Computational Optimization and Applications, 83, 143-180, 2022.</p>
</li>
<li><p> J.N. Wang, X. Wang and L.W. Zhang.<br />
  A stochastic Newton method for nonlinear equations.<br />
  Journal of Computational Mathematics, 2022.</p>
</li>
<li><p> F. He, X. Wang and X. Chen.<br />
  A penalty relaxation method for image processing using Euler's Elastica Model.<br />
  SIAM Journal on Imaging Sciences, 14(1), 389-417, 2021.</p>
</li>
<li><p> X. Wang and H. Zhang.<br />
  Inexact proximal stochastic second-order methods for nonconvex composite optimization.<br />
  Optimization Methods and Software, 35(4), 808-835, 2020.</p>
</li>
<li><p> Y. Liu, X. Wang and T.D. Guo.<br />
  A linearly convergent stochastic recursive gradient method for convex optimization.<br />
  Optimization Letters, 14: 2265-2283, 2020.</p>
</li>
<li><p> X.Y. Wang, X. Wang and Y. Yuan.<br />
  Stochastic Proximal Quasi-Newton methods for Nonconvex Composite Optimization.<br />
  Optimization Methods and Software, 34: 922-948，2019.</p>
</li>
<li><p> X. Wang, S. Ma, D. Goldfarb and W. Liu.<br />
  Stochastic quasi-Newton methods for nonconvex stochastic optimization.<br />
  SIAM Journal on Optimization, 27(2), pp 927-956, 2017.</p>
</li>  
<li><p> X. Wang, S. Ma and Y. Yuan.<br />
  Penalty methods with stochastic approximation for stochastic nonlinear programming.<br />
  Mathematics of Computation, 86, pp 1793-1820, 2017.</p>
</li> 
<li><p> X. Wang, S. Wang and H. Zhang.<br />
  Inexact proximal stochastic gradient method for convex composite optimization.<br />
  Computational Optimization and Applications, 68: 579-618, 2017.</p>
</li>  
<li><p> X. Wang and H. Zhang.<br />
  An augmented Lagrangian affine scaling method for nonlinear programming.<br />
  Optimization Methods and Software, 30(5), 934-964, 2015.</p>
</li>
<li><p> X. Wang and Y. Yuan.<br />
  An augmented Lagrangian trust region method for equality constrained optimization.<br />
  Optimization Methods and Software, 30(3), pp 559-582, 2015.</p>
</li>
<li><p> X. Liu, Z. Wen, X. Wang, M. Ulbrich and Y. Yuan.<br />
  On the Analysis of the Discretized Kohn-Sham Density Functional Theory.<br />
  SIAM Journal on Numerical Analysis, 53(4), pp 1758-1785, 2015.</p>
</li>
<li><p> X. Liu, X. Wang, Z. Wen and Y. Yuan.<br />
  On the convergence of the self-consistent field iteration in Kohn-Sham density functional theory.<br />
  SIAM Journal on Matrix Analysis and Applications, 35-2, pp. 546-558, 2014.</p>
</li>
<li><p> X. Wang, Y. Yuan.<br />
  A trust region method based on a new affine scaling technique for simple bounded optimization.<br />
  Optimization Methods and Software, 28(4), pp 871-888, 2013.</p>
</li>
<li><p> X. Wang.<br />
  A trust region affine scaling method for bound constrained optimization.<br />
  Acta Mathematica Sinica, English Series, 29(1), pp 159-182, 2013.</p>
</li>
<li><p> X. Huang, Z. Lei, M. Fan, X. Wang and S.Z. Li.<br />
  A Regularized Discriminative Spectral Regression Method for Heterogeneous Face Matching.<br />
  IEEE Transaction on Image Processing, 22(1), pp 353-362, 2013. </p>
</li>
</ul>
<h2>Chinese(中文)</h2>
<ul>
<li><p> 王晓.<br />
  非凸约束优化的随机近似算法.<br />
  运筹学学报，2023. </p>
</li>
<li><p> 王晓.<br />
  求解一般界约束优化问题的积极集信赖域方法.<br />
  中国科学，第41 卷，第4 期，377-391，2011. </p>
</li>
</ul> 
<div id="footer">
<div id="footer-text">
Page generated 2020-06-15 13:24:19 CST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
